{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from func import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(data = 'musical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10261, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove the \n",
    "def text_normalization(doc):\n",
    "    '''\n",
    "    lemmentize the words and also remove the stopwords and punctuation\n",
    "    '''\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    punctuations = string.punctuation\n",
    "    doc = nlp(doc, disable=['parser', 'ner'])\n",
    "    tokens = [tok.lemma_.lower().strip() for tok in doc if tok.lemma_ != '-PRON-']\n",
    "    tokens = [tok for tok in tokens if tok not in spacy_stopwords and tok not in punctuations]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens\n",
    "normalize_corpus = np.vectorize(text_normalization)\n",
    "df['reviewText_norm'] = normalize_corpus(df['reviewText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def doc_normalization(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
    "    return doc\n",
    "normalize_corpus2 = np.vectorize(doc_normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviewText_norm1'] = normalize_corpus2(df['reviewText_norm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10261, 11)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['reviewText_norm1']\n",
    "y = df['overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of the Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,4))\n",
    "sns.barplot(x = y.unique(), y=y.value_counts())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the Most Frequent words for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFO_text = [text for text in X_train[X_train['Conference'] == 'INFOCOM']['Title']]\n",
    "IS_text = [text for text in train[train['Conference'] == 'ISCAS']['Title']]\n",
    "INFO_clean = cleanup_text(INFO_text)\n",
    "INFO_clean = ' '.join(INFO_clean).split()\n",
    "IS_clean = cleanup_text(IS_text)\n",
    "IS_clean = ' '.join(IS_clean).split()\n",
    "INFO_counts = Counter(INFO_clean)\n",
    "IS_counts = Counter(IS_clean)\n",
    "INFO_common_words = [word[0] for word in INFO_counts.most_common(20)]\n",
    "INFO_common_counts = [word[1] for word in INFO_counts.most_common(20)]\n",
    "fig = plt.figure(figsize=(18,6))\n",
    "sns.barplot(x=INFO_common_words, y=INFO_common_counts)\n",
    "plt.title('Most Common Words used in the research papers for conference INFOCOM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the necessary modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 53)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['able', 'absolutely', 'ac', 'accurate', 'acoustic', 'acoustic electric', 'acoustic guitar', 'action', 'actually', 'adapter', 'add', 'adjust', 'adjustable', 'adjustment', 'advertise', 'ago', 'allow', 'amazing', 'amazon', 'amp', 'angle', 'apart', 'appear', 'arm', 'arrive', 'ask', 'attach', 'audio', 'available', 'away', 'awesome', 'bad', 'bag', 'ball', 'band', 'bar', 'base', 'basic', 'basically', 'bass', 'battery', 'beat', 'beginner', 'behringer', 'believe', 'bend', 'best', 'better', 'big', 'bit', 'black', 'blue', 'board', 'body', 'boost', 'boss', 'box', 'brand', 'break', 'bridge', 'bright', 'bring', 'buck', 'budget', 'build', 'build quality', 'button', 'buy', 'buzz', 'cable', 'capo', 'care', 'carry', 'case', 'cause', 'center', 'certainly', 'chain', 'change', 'change string', 'channel', 'cheap', 'check', 'choice', 'choose', 'chord', 'clamp', 'classic', 'clean', 'clear', 'clip', 'close', 'cloth', 'color', 'come', 'comfortable', 'compact', 'company', 'compare', 'complain', 'complaint', 'completely', 'computer', 'connect', 'connection', 'connector', 'consider', 'construction', 'control', 'cool', 'cord', 'cost', 'couple', 'course', 'cover', 'cut', 'daddario', 'damage', 'day', 'deal', 'decent', 'decide', 'definitely', 'delay', 'deliver', 'depend', 'design', 'device', 'dial', 'difference', 'different', 'difficult', 'digital', 'display', 'distortion', 'dollar', 'double', 'drive', 'drop', 'drum', 'dunlop', 'durable', 'duty', 'ear', 'easily', 'easy', 'easy use', 'edge', 'effect', 'electric', 'electric guitar', 'elixir', 'end', 'enjoy', 'epiphone', 'eq', 'equipment', 'ernie', 'especially', 'exactly', 'excellent', 'expect', 'expensive', 'experience', 'extra', 'extremely', 'fact', 'fail', 'fairly', 'fall', 'fan', 'fantastic', 'far', 'fast', 'favorite', 'feature', 'feel', 'feel like', 'fender', 'figure', 'filter', 'finally', 'fine', 'finger', 'finish', 'fit', 'fix', 'flat', 'flexible', 'floor', 'fold', 'foot', 'free', 'fret', 'friend', 'fun', 'function', 'gain', 'gauge', 'gear', 'gibson', 'gig', 'gig bag', 'glad', 'good', 'good price', 'good quality', 'good sound', 'great', 'great price', 'great product', 'great sound', 'grip', 'guess', 'guitar', 'guitar case', 'guitar pick', 'guitar player', 'guitar sound', 'guitar stand', 'guitar strap', 'guitar string', 'guitarist', 'guy', 'half', 'hand', 'handle', 'handy', 'hang', 'happen', 'happy', 'hard', 'head', 'headphone', 'headstock', 'hear', 'heavy', 'help', 'high', 'high end', 'high quality', 'highly', 'highly recommend', 'hit', 'hold', 'holder', 'hole', 'home', 'hook', 'hope', 'hour', 'house', 'huge', 'idea', 'impressed', 'improve', 'inch', 'include', 'inexpensive', 'input', 'inside', 'instal', 'install', 'instead', 'instrument', 'interface', 'issue', 'item', 'jack', 'jam', 'jazz', 'job', 'just', 'just fine', 'just like', 'just right', 'key', 'keyboard', 'kind', 'knob', 'know', 'large', 'later', 'lead', 'learn', 'leather', 'leave', 'length', 'les', 'les paul', 'let', 'level', 'life', 'light', 'like', 'likely', 'line', 'little', 'little bit', 'live', 'local', 'lock', 'long', 'long time', 'longer', 'look', 'look good', 'look great', 'look like', 'loop', 'loose', 'lose', 'lot', 'loud', 'love', 'low', 'main', 'make', 'make easy', 'make sure', 'mandolin', 'martin', 'match', 'material', 'matter', 'maybe', 'mean', 'medium', 'mention', 'mess', 'metal', 'mic', 'mic stand', 'microphone', 'mid', 'mind', 'mini', 'minute', 'miss', 'mix', 'mixer', 'mm', 'model', 'money', 'month', 'mount', 'music', 'musician', 'mxr', 'near', 'neck', 'need', 'new', 'nice', 'nicely', 'noise', 'non', 'normal', 'note', 'notice', 'nut', 'nylon', 'offer', 'ok', 'old', 'open', 'opinion', 'option', 'order', 'original', 'output', 'overall', 'overdrive', 'pack', 'package', 'pad', 'padding', 'particular', 'past', 'patch', 'paul', 'pay', 'pedal', 'pedal board', 'peg', 'people', 'perfect', 'perfectly', 'perform', 'performance', 'pick', 'pickup', 'picture', 'piece', 'pin', 'pitch', 'place', 'plan', 'planet', 'planet waves', 'plastic', 'play', 'play guitar', 'player', 'playing', 'pleased', 'plenty', 'plug', 'plus', 'pocket', 'point', 'pop', 'portable', 'position', 'power', 'power supply', 'practice', 'prefer', 'pretty', 'pretty good', 'price', 'pro', 'probably', 'problem', 'produce', 'product', 'professional', 'properly', 'protect', 'provide', 'pull', 'purchase', 'purpose', 'push', 'quality', 'quick', 'quickly', 'quiet', 'quite', 'range', 'rate', 'read', 'real', 'really', 'really good', 'really like', 'really nice', 'reason', 'receive', 'recently', 'recommend', 'record', 'recording', 'red', 'regular', 'remove', 'replace', 'replacement', 'require', 'rest', 'result', 'return', 'reverb', 'review', 'reviewer', 'rich', 'right', 'rock', 'room', 'rubber', 'run', 'save', 'say', 'screw', 'second', 'secure', 'sell', 'send', 'set', 'setting', 'setup', 'shape', 'ship', 'shipping', 'shop', 'short', 'shure', 'signal', 'similar', 'simple', 'simply', 'single', 'sit', 'size', 'slide', 'slightly', 'slip', 'small', 'smooth', 'snark', 'soft', 'software', 'solid', 'son', 'song', 'soon', 'sort', 'sound', 'sound good', 'sound great', 'sound like', 'sound quality', 'sounding', 'space', 'speaker', 'spend', 'spot', 'spring', 'stable', 'stage', 'stand', 'standard', 'star', 'start', 'state', 'stay', 'stay tune', 'steel', 'stick', 'stiff', 'stock', 'stop', 'store', 'straight', 'strap', 'strap lock', 'strat', 'string', 'string guitar', 'string sound', 'string use', 'strong', 'studio', 'stuff', 'sturdy', 'style', 'suggest', 'super', 'supply', 'support', 'suppose', 'sure', 'surface', 'surprised', 'sustain', 'sweet', 'switch', 'tell', 'tend', 'tension', 'test', 'thank', 'thickness', 'thing', 'think', 'tight', 'time', 'tip', 'tone', 'tool', 'totally', 'touch', 'track', 'travel', 'true', 'try', 'tube', 'tube amp', 'tune', 'tuner', 'tuning', 'turn', 'type', 'uke', 'ukulele', 'unit', 'unless', 'update', 'upgrade', 'usb', 'use', 'use guitar', 'useful', 'user', 'usually', 'value', 'variety', 'various', 'versatile', 'version', 'video', 'vintage', 'vocal', 'voice', 'volume', 'wall', 'want', 'warm', 'wave', 'waves', 'way', 'wear', 'week', 'weight', 'wide', 'wire', 'wish', 'wonderful', 'wood', 'work', 'work fine', 'work great', 'work just', 'work perfectly', 'worry', 'worth', 'wow', 'write', 'wrong', 'xlr', 'year', 'year ago', 'yes']\n"
     ]
    }
   ],
   "source": [
    "# Initialize a CountVectorizer object: count_vectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words = \"english\", ngram_range=(1, 2), min_df=.01, max_df=.99)\n",
    "\n",
    "# Transform the training data using only the 'text' column values: count_train \n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using only the 'tex t' column values: count_test \n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "\n",
    "# Print the first 10 features of the count_vectorizer\n",
    "print(count_vectorizer.get_feature_names()[:700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "633"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6874, 633)"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_train.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words = set(count_vectorizer.get_feature_names()[:700])\n",
    "\n",
    "# X_train1 = X_train.apply(lambda sentence: \n",
    "#                          ' '.join([word for word in sentence.split() if word.lower() not in stop_words])) #\n",
    "\n",
    "# X_train\n",
    "\n",
    "# X_train1\n",
    "\n",
    "# X_test1 = X_test.apply(lambda sentence: \n",
    "#                        ' '.join([word for word in sentence.split() if word.lower() not in stop_words])) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize a CountVectorizer object: count_vectorizer\n",
    "# count_vectorizer1 = CountVectorizer(stop_words = \"english\")\n",
    "\n",
    "# # Transform the training data using only the 'text' column values: count_train \n",
    "# count_train = count_vectorizer1.fit_transform(X_train1)\n",
    "\n",
    "# # Transform the test data using only the 'tex t' column values: count_test \n",
    "# count_test = count_vectorizer1.transform(X_test1)\n",
    "\n",
    "# # Print the first 10 features of the count_vectorizer\n",
    "# print(count_vectorizer1.get_feature_names()[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZYe/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/ZYe/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn import metrics\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "            'prec': 'precision'}\n",
    "\n",
    "# Instantiate a Multinomial Naive Bayes classifier: lr_classifier\n",
    "lr_classifier = LogisticRegression(C=1e5, solver='newton-cg', multi_class='multinomial') \n",
    "                    #, class_weight = weights)\n",
    "\n",
    "scores = cross_validate(lr_classifier, count_train, y_train, cv=3,\n",
    "                         scoring=['accuracy', 'f1_weighted'],\n",
    "                         return_train_score=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.33208585, 0.32400393, 0.24904299]),\n",
       " 'score_time': array([0.00259519, 0.00169301, 0.002002  ]),\n",
       " 'test_accuracy': array([0.66768426, 0.67568747, 0.67641921]),\n",
       " 'train_accuracy': array([0.6780179 , 0.67706742, 0.67822862]),\n",
       " 'test_f1_weighted': array([0.54921086, 0.55338102, 0.55846713]),\n",
       " 'train_f1_weighted': array([0.55869991, 0.55555631, 0.56038014])}"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_classifier.coef_\n",
    "\n",
    "feature_names = count_vectorizer.get_feature_names()\n",
    "coefs_with_fns = sorted(zip(lr_classifier.coef_[1], feature_names))\n",
    "\n",
    "def printNMostInformative(vectorizer, clf, N):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns_1 = sorted(zip(clf.coef_[0], feature_names))\n",
    "    coefs_with_fns_2 = sorted(zip(clf.coef_[1], feature_names))\n",
    "    coefs_with_fns_3 = sorted(zip(clf.coef_[2], feature_names))\n",
    "    coefs_with_fns_4 = sorted(zip(clf.coef_[3], feature_names))\n",
    "    coefs_with_fns_5 = sorted(zip(clf.coef_[4], feature_names))\n",
    "    topClass1 = coefs_with_fns_1[:N]\n",
    "    topClass2 = coefs_with_fns_2[:N]\n",
    "    topClass3 = coefs_with_fns_3[:N]\n",
    "    topClass4 = coefs_with_fns_4[:N]\n",
    "    topClass5 = coefs_with_fns_5[:N]\n",
    "    print(\"Class 1 best: \")\n",
    "    for feat in topClass1:\n",
    "        print(feat)\n",
    "    print(\"Class 2 best: \")\n",
    "    for feat in topClass2:\n",
    "        print(feat)\n",
    "    print(\"Class 3 best: \")\n",
    "    for feat in topClass3:\n",
    "        print(feat)\n",
    "    print(\"Class 4 best: \")\n",
    "    for feat in topClass4:\n",
    "        print(feat)\n",
    "    print(\"Class 5 best: \")\n",
    "    for feat in topClass5:\n",
    "        print(feat)\n",
    "\n",
    "printNMostInformative(count_vectorizer, lr_classifier, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize a TfidfVectorizer object: tfidf_vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1, 2), max_df=0.99, min_df=0.01)\n",
    "\n",
    "# Transform the training data: tfidf_train \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data: tfidf_test \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Print the first 10 features\n",
    "print(tfidf_vectorizer.get_feature_names()[:10])\n",
    "\n",
    "# Print the first 5 vectors of the tfidf training data\n",
    "print(tfidf_train.A[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CountVectorizer DataFrame: count_df\n",
    "count_df = pd.DataFrame(count_train.A, columns=count_vectorizer.get_feature_names())\n",
    "\n",
    "# Create the TfidfVectorizer DataFrame: tfidf_df\n",
    "tfidf_df = pd.DataFrame(tfidf_train.A, columns=tfidf_vectorizer.get_feature_names())\n",
    "\n",
    "# Print the head of count_df\n",
    "print(count_df.head())\n",
    "\n",
    "# Print the head of tfidf_df\n",
    "print(tfidf_df.head())\n",
    "\n",
    "# Calculate the difference in columns: difference\n",
    "difference = set(count_df.columns) - set(tfidf_df.columns)\n",
    "print(difference)\n",
    "\n",
    "# Check whether the DataFrames are equal\n",
    "print(count_df.equals(tfidf_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Multinomial Naive Bayes classifier: lr_classifier\n",
    "lr_classifier = LogisticRegression(C=1e5, solver='newton-cg', multi_class='multinomial') \n",
    "                    #, class_weight = weights)\n",
    "\n",
    "scores = cross_validate(lr_classifier, tfidf_train, y_train, cv=3,\n",
    "                         scoring=['accuracy', 'f1_weighted'],\n",
    "                         return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([8.70167112, 9.3029089 , 7.52045417]),\n",
       " 'score_time': array([0.00242686, 0.00211096, 0.00213671]),\n",
       " 'test_accuracy': array([0.60052333, 0.6001746 , 0.60305677]),\n",
       " 'train_accuracy': array([0.7987339 , 0.8020947 , 0.79057592]),\n",
       " 'test_f1_weighted': array([0.59032733, 0.58622763, 0.59111767]),\n",
       " 'train_f1_weighted': array([0.7828489 , 0.7856703 , 0.77327812])}"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6194272217301446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ZYe/anaconda3/lib/python3.7/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a Multinomial Naive Bayes classifier: lr_classifier\n",
    "lr_classifier = LogisticRegression(C=1e5, solver='newton-cg', multi_class='multinomial')\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "lr_classifier.fit(count_train,y_train)\n",
    "\n",
    "# Create the predicted tags: pred\n",
    "pred = lr_classifier.predict(count_test)\n",
    "\n",
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "# from sklearn.metrics import multilabel_confusion_matrix\n",
    "# cm = multilabel_confusion_matrix(y_test, pred, labels=['1Star',\"2Star\", '3Star', '4Star', '5Star'])\n",
    "# print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
